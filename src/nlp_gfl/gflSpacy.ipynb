{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Constants\n",
    "DEFAULT_PRONOUNS = {\n",
    "    \"male\": {\"subject\": \"he\", \"object\": \"him\", \"possessive\": \"his\", \"reflexive\": \"himself\"},\n",
    "    \"female\": {\"subject\": \"she\", \"object\": \"her\", \"possessive\": \"her\", \"reflexive\": \"herself\"},\n",
    "    \"gender_fair\": {\"subject\": \"they\", \"object\": \"them\", \"possessive\": \"their\", \"reflexive\": \"themselves\"}\n",
    "}\n",
    "\n",
    "GENDER_ADJECTIVES = {\"male\", \"female\", \"lady\", \"gentlemen\", \"boy\", \"girl\", \"man\", \"woman\", \"lady's\"}\n",
    "GENDER_PAIRS = {\n",
    "    (\"girl\", \"boy\"): [\"children\", \"kids\", \"students\", \"youth\", \"young people\"],\n",
    "    (\"son\", \"daughter\"): [\"children\", \"kids\", \"offspring\"],\n",
    "    (\"woman\", \"man\"): [\"people\", \"individuals\", \"persons\"],\n",
    "    (\"women\", \"men\"): [\"people\", \"individuals\", \"persons\"],\n",
    "    (\"he\", \"she\"): [\"they\"],\n",
    "    (\"his\", \"her\"): [\"their\"],\n",
    "    (\"him\", \"her\"): [\"them\"],\n",
    "    (\"himself\", \"herself\"): [\"themselves\"],\n",
    "    (\"husband\", \"wife\"): [\"spouse\", \"partner\"],\n",
    "    (\"boyfriend\", \"girlfriend\"): [\"partner\"],\n",
    "    (\"brother\", \"sister\"): [\"sibling\"],\n",
    "    (\"father\", \"mother\"): [\"parent\"],\n",
    "    (\"uncle\", \"aunt\"): [\"relative\"],\n",
    "    (\"nephew\", \"niece\"): [\"relative\"],\n",
    "    (\"ladies\", \"gentlemen\"): [\"everyone\", \"all\"]\n",
    "}\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class GenderFairLanguage:\n",
    "    def __init__(self, terms_csv: str = 'gendered_terms.csv'):\n",
    "        self.gendered_terms = self._load_and_prioritize_terms(terms_csv)\n",
    "        \n",
    "    def _load_and_prioritize_terms(self, csv_filename: str) -> OrderedDict:\n",
    "        \"\"\"Load and prioritize gendered terms from CSV with multiple replacements.\"\"\"\n",
    "        gendered_terms = OrderedDict()\n",
    "        try:\n",
    "            with open(csv_filename, 'r') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                for row in reader:\n",
    "                    if len(row) >= 2:\n",
    "                        term = row[0].strip().lower()\n",
    "                        replacements = [repl.strip() for repl in row[1:] if repl.strip()]\n",
    "                        if term and replacements:\n",
    "                            gendered_terms[term] = replacements\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading gendered terms: {e}\")\n",
    "            \n",
    "        return OrderedDict(\n",
    "            sorted(gendered_terms.items(), key=lambda item: len(item[0].split()), reverse=True)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _adjust_capitalization(original: str, replacement: str) -> str:\n",
    "        \"\"\"Preserve capitalization patterns in replacements.\"\"\"\n",
    "        if original.isupper():\n",
    "            return replacement.upper()\n",
    "        elif original.istitle():\n",
    "            return replacement.capitalize()\n",
    "        return replacement.lower()\n",
    "\n",
    "    def _is_within_quotes(self, doc, start_idx: int, end_idx: int) -> bool:\n",
    "        \"\"\"Check if text is within double quotes in the original text.\"\"\"\n",
    "        text = doc.text\n",
    "        before = len(re.findall(r'(?<!\\\\)\"', text[:start_idx]))\n",
    "        after = len(re.findall(r'(?<!\\\\)\"', text[end_idx:]))\n",
    "        return (before % 2 == 1) and (after % 2 == 1)\n",
    "\n",
    "    def _process_text_replacements(self, text: str, name_pronoun_map: Dict) -> Tuple[str, List[Dict]]:\n",
    "        \"\"\"Main text processing with hyphen-aware name handling.\"\"\"\n",
    "        doc = nlp(text)\n",
    "        # Enhanced title detection with hyphen handling\n",
    "\n",
    "        TITLE_MAPPING = {\n",
    "                        'mr': 'male',\n",
    "                        'ms': 'female', \n",
    "                        'mrs': 'female', \n",
    "                        'mx': 'gender_fair',\n",
    "                        'sir': 'male',\n",
    "                        'madam': \"female\",\n",
    "                         }\n",
    "        i = 0\n",
    "        while i < len(doc):\n",
    "            token = doc[i]\n",
    "            base_title = token.text.lower().rstrip('.')\n",
    "\n",
    "            if base_title in TITLE_MAPPING:\n",
    "                name_parts = [token.text]\n",
    "                j = i + 1\n",
    "                hyphen_buffer = None  # Track hyphens for merging\n",
    "\n",
    "                while j < len(doc):\n",
    "                    current_token = doc[j]\n",
    "                    current_text = current_token.text\n",
    "\n",
    "                    # Handle hyphen merging\n",
    "                    if current_text == '-':\n",
    "                        hyphen_buffer = current_text\n",
    "                    elif hyphen_buffer and current_token.pos_ == 'PROPN':\n",
    "                        # Merge hyphen with next word\n",
    "                        name_parts.append(hyphen_buffer + current_text)\n",
    "                        hyphen_buffer = None\n",
    "                    elif current_token.pos_ == 'PROPN' or (current_text in ['-'] and not hyphen_buffer):\n",
    "                        name_parts.append(current_text)\n",
    "                    else:\n",
    "                        break\n",
    "                    \n",
    "                    j += 1\n",
    "\n",
    "                if len(name_parts) > 1:\n",
    "                    # Clean and normalize names\n",
    "                    full_name = self._normalize_hyphenated_name(' '.join(name_parts))\n",
    "                    name_without_title = self._normalize_hyphenated_name(' '.join(name_parts[1:]))\n",
    "\n",
    "                    category = TITLE_MAPPING[base_title]\n",
    "                    name_pronoun_map[full_name.lower()] = category\n",
    "                    name_pronoun_map[name_without_title.lower()] = category\n",
    "\n",
    "                i = j - 1  # Skip processed tokens\n",
    "            i += 1\n",
    "\n",
    "        # Rest of processing remains\n",
    "        corrections = []\n",
    "        corrections.extend(self._find_gender_pairs(text, doc))\n",
    "        corrections.extend(self._find_adjective_noun_pairs(text, doc))\n",
    "        corrections.extend(self._find_individual_terms(text, doc))\n",
    "        corrections.extend(self._find_pronoun_replacements(text, doc, name_pronoun_map))\n",
    "        corrections = self._filter_overlapping_corrections(corrections)\n",
    "\n",
    "        revised_text = text\n",
    "        for correction in sorted(corrections, key=lambda x: -x['character_offset']):\n",
    "            replacement_str = correction['replacements'][0]\n",
    "            revised_text = revised_text[:correction['character_offset']] + replacement_str + revised_text[correction['character_endset']:]\n",
    "\n",
    "        return revised_text, corrections\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_hyphenated_name(name: str) -> str:\n",
    "        \"\"\"Merge hyphen patterns into proper hyphenated format.\"\"\"\n",
    "        return re.sub(r'\\s*-\\s*', '-', name).strip()\n",
    "\n",
    "    def _find_pronoun_replacements(self, text: str, doc, name_pronoun_map: Dict) -> List[Dict]:\n",
    "        \"\"\"Pronoun resolution with enhanced name tracking.\"\"\"\n",
    "        corrections = []\n",
    "        name_to_category = {name.lower(): category for name, category in name_pronoun_map.items()}\n",
    "        processed_names = set(name_to_category.keys())\n",
    "\n",
    "        # Track all name variants from titles\n",
    "        name_variants = []\n",
    "        for name in processed_names:\n",
    "            name_variants.extend([\n",
    "                name,\n",
    "                name.replace('-', ' '),  # \"adam-silver\" -> \"adam silver\"\n",
    "                name.replace(' ', '-')    # \"adam silver\" -> \"adam-silver\"\n",
    "            ])\n",
    "\n",
    "        NEUTRAL_PRONOUNS = {\"i\", \"me\", \"my\", \"mine\", \"myself\",\n",
    "                            \"we\", \"us\", \"our\", \"ours\", \"ourselves\",\n",
    "                            \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "                            \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"it\", \"its\", \"itself\"}\n",
    "\n",
    "        for token in doc:\n",
    "            if (token.tag_ in [\"PRP\", \"PRP$\"] and \n",
    "                token.text.lower() not in NEUTRAL_PRONOUNS and\n",
    "                not self._is_within_quotes(doc, token.idx, token.idx + len(token.text))):\n",
    "\n",
    "                # Find closest matching name in previous context\n",
    "                referent = None\n",
    "                lookback_window = doc[max(0, token.i-10):token.i]  # 10 tokens back\n",
    "                for prev_token in reversed(lookback_window):\n",
    "                    if prev_token.pos_ == 'PROPN':\n",
    "                        candidate = self._normalize_hyphenated_name(prev_token.text).lower()\n",
    "                        if candidate in processed_names:\n",
    "                            referent = candidate\n",
    "                            break\n",
    "                        # Check space/hyphen variants\n",
    "                        for variant in [candidate, candidate.replace('-', ' ')]:\n",
    "                            if variant in name_to_category:\n",
    "                                referent = variant\n",
    "                                break\n",
    "                        if referent:\n",
    "                            break\n",
    "\n",
    "                # Fallback to entity resolution\n",
    "                if not referent:\n",
    "                    for ent in reversed(doc.ents):\n",
    "                        if ent.end <= token.i and ent.label_ in [\"PERSON\", \"ORG\"]:\n",
    "                            candidate = self._normalize_hyphenated_name(ent.text).lower()\n",
    "                            if candidate in processed_names:\n",
    "                                referent = candidate\n",
    "                                break\n",
    "\n",
    "                # Determine pronoun role and replacement\n",
    "                if referent:\n",
    "                    category = name_to_category[referent]\n",
    "                    role = self._get_pronoun_role(token)\n",
    "                    new_pronoun = DEFAULT_PRONOUNS[category][role]\n",
    "                else:\n",
    "                    new_pronoun = DEFAULT_PRONOUNS[\"gender_fair\"][self._get_pronoun_role(token)]\n",
    "\n",
    "                # Apply capitalization and replacement\n",
    "                new_pronoun = self._adjust_capitalization(token.text, new_pronoun)\n",
    "                if new_pronoun != token.text:\n",
    "                    corrections.append({\n",
    "                        \"word_index\": token.i,\n",
    "                        \"original_text\": token.text,\n",
    "                        \"replacements\": [new_pronoun],\n",
    "                        \"character_offset\": token.idx,\n",
    "                        \"character_endset\": token.idx + len(token.text)\n",
    "                    })\n",
    "\n",
    "        return corrections\n",
    "\n",
    "    def _get_pronoun_role(self, token) -> str:\n",
    "        \"\"\"Determine pronoun grammatical role.\"\"\"\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "            return \"subject\"\n",
    "        if token.dep_ in [\"dobj\", \"iobj\", \"pobj\"]:\n",
    "            return \"object\"\n",
    "        if token.dep_ == \"poss\" or token.tag_ == \"PRP$\":\n",
    "            return \"possessive\"\n",
    "        if token.dep_ == \"reflexive\":\n",
    "            return \"reflexive\"\n",
    "        return \"subject\"  # Default fallback\n",
    "\n",
    "    def _find_gender_pairs(self, text: str, doc) -> List[Dict]:\n",
    "        \"\"\"Find specific gender pairs to replace with more inclusive terms.\"\"\"\n",
    "        corrections = []\n",
    "\n",
    "        for (term1, term2), replacements in GENDER_PAIRS.items():\n",
    "             for t1, t2 in [(term1, term2), (term2, term1)]:\n",
    "                term1_variants = [t1, t1 + 's', t1 + 'es']\n",
    "                term2_variants = [t2, t2 + 's', t2 + 'es']\n",
    "\n",
    "                for v1 in term1_variants:\n",
    "                    for v2 in term2_variants:\n",
    "                        pattern = rf'\\b({v1})\\s+(and|or)\\s+({v2})\\b'\n",
    "                        matches = list(re.finditer(pattern, text, re.IGNORECASE))\n",
    "\n",
    "                        for match in reversed(matches):\n",
    "                            if self._is_within_quotes(doc, match.start(), match.end()):\n",
    "                                continue\n",
    "\n",
    "                            is_or = match.group(2).lower() == \"or\"\n",
    "\n",
    "                            # Handle singular/plural for \"or\" cases\n",
    "                            if is_or:\n",
    "                                adjusted_replacements = []\n",
    "                                for repl in replacements:\n",
    "                                    if repl.endswith('s'):\n",
    "                                        adjusted = repl[:-1]  # children -> child\n",
    "                                    elif repl.endswith('es'):\n",
    "                                        adjusted = repl[:-2]  # ladies -> lady\n",
    "                                    else:\n",
    "                                        adjusted = repl\n",
    "                                    adjusted_replacements.append(adjusted)\n",
    "                            else:\n",
    "                                adjusted_replacements = replacements\n",
    "\n",
    "                            first_word = match.group(1)\n",
    "                            adjusted_replacements = [\n",
    "                                self._adjust_capitalization(first_word, repl)\n",
    "                                for repl in adjusted_replacements\n",
    "                            ]\n",
    "\n",
    "                            corrections.append({\n",
    "                                \"word_index\": next((i for i, t in enumerate(doc) if t.idx <= match.start() < t.idx + len(t.text)), None),\n",
    "                                \"original_text\": match.group(0),\n",
    "                                \"replacements\": adjusted_replacements,\n",
    "                                \"character_offset\": match.start(),\n",
    "                                \"character_endset\": match.end()\n",
    "                            })\n",
    "\n",
    "        return corrections\n",
    "\n",
    "\n",
    "    def _find_adjective_noun_pairs(self, text: str, doc) -> List[Dict]:\n",
    "        \"\"\"Handle possessive forms and compound gender terms.\"\"\"\n",
    "        corrections = []\n",
    "        GENDER_ADJECTIVES_PAIR_REMOVAL = {\"male\", \"female\", \"lady\", \"gentlemen\", \"boy\", \"girl\"}\n",
    "\n",
    "        for i in range(len(doc) - 2):  # Look ahead for possessive forms\n",
    "            token = doc[i]\n",
    "            next_token = doc[i + 1]\n",
    "            next_next_token = doc[i + 2] if i+2 < len(doc) else None\n",
    "\n",
    "            # Handle possessive forms like \"lady's room\"\n",
    "            if (token.text.lower() in GENDER_ADJECTIVES_PAIR_REMOVAL and\n",
    "                next_token.text == \"'s\" and \n",
    "                next_next_token and \n",
    "                next_next_token.pos_ == \"NOUN\"):\n",
    "\n",
    "                full_phrase = f\"{token.text}{next_token.text} {next_next_token.text}\"\n",
    "                replacement = self._adjust_pluralization(token.text, next_next_token.text)\n",
    "\n",
    "                corrections.append({\n",
    "                    \"word_index\": i,\n",
    "                    \"original_text\": full_phrase,\n",
    "                    \"replacements\": [replacement],\n",
    "                    \"character_offset\": token.idx,\n",
    "                    \"character_endset\": next_next_token.idx + len(next_next_token.text)\n",
    "                })\n",
    "\n",
    "        \n",
    "        return corrections\n",
    "\n",
    "    def _find_individual_terms(self, text: str, doc) -> List[Dict]:\n",
    "        \"\"\"Enhanced regex for possessive terms.\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        for term, replacements in self.gendered_terms.items():\n",
    "            # Handle possessive terms in CSV like \"lady's room\"\n",
    "            term_pattern = term.replace(\"'\", r\"['â€™]\")  # Match different apostrophe types\n",
    "            pattern = r'(?i)(?<!\\w)({})(?!\\w)'.format(re.escape(term_pattern))\n",
    "    \n",
    "            continue\n",
    "        \n",
    "        for match in reversed(list(re.finditer(rf'\\b{re.escape(term)}\\b', text, re.IGNORECASE))):\n",
    "            if self._is_within_quotes(doc, match.start(), match.end()):\n",
    "                continue\n",
    "            \n",
    "            original_text = match.group(0)\n",
    "            adjusted_replacements = [self._adjust_capitalization(original_text, repl) for repl in replacements_list]\n",
    "            \n",
    "            corrections.append({\n",
    "                \"word_index\": next((i for i, t in enumerate(doc) if t.idx <= match.start() < t.idx + len(t.text)), None),\n",
    "                \"original_text\": original_text,\n",
    "                \"replacements\": adjusted_replacements,\n",
    "                \"character_offset\": match.start(),\n",
    "                \"character_endset\": match.end()\n",
    "            })\n",
    "    \n",
    "        return corrections\n",
    "\n",
    "    def _find_pronoun_replacements(self, text: str, doc, name_pronoun_map: Dict) -> List[Dict]:\n",
    "        \"\"\"Find pronoun replacements with fallback to gender-fair language.\"\"\"\n",
    "        corrections = []\n",
    "        name_to_category = {name.lower(): category for name, category in (name_pronoun_map or {}).items()}\n",
    "\n",
    "        person_entities = [ent for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\"]]\n",
    "        NEUTRAL_PRONOUNS = {\"i\", \"me\", \"my\", \"mine\", \"myself\",\n",
    "                            \"we\", \"us\", \"our\", \"ours\", \"ourselves\",\n",
    "                            \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "                            \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"it\", \"its\", \"itself\"}\n",
    "\n",
    "        for token in doc:\n",
    "            if (token.tag_ in [\"PRP\", \"PRP$\"] and \n",
    "                token.text.lower() not in NEUTRAL_PRONOUNS and\n",
    "                not self._is_within_quotes(doc, token.idx, token.idx + len(token.text))):\n",
    "\n",
    "                referent = None\n",
    "                for ent in reversed(person_entities[:token.i]):\n",
    "                    if ent.end <= token.i:\n",
    "                        referent = ent.text\n",
    "                        break\n",
    "                \n",
    "                if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "                    role = \"subject\"\n",
    "                elif token.dep_ in [\"dobj\", \"iobj\", \"pobj\"]:\n",
    "                    role = \"object\"\n",
    "                elif token.dep_ == \"poss\" or token.tag_ == \"PRP$\":\n",
    "                    role = \"possessive\"\n",
    "                elif token.dep_ == \"reflexive\":\n",
    "                    role = \"reflexive\"\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                if referent and referent.lower() in name_to_category:\n",
    "                    category = name_to_category[referent.lower()]\n",
    "                    new_pronoun = DEFAULT_PRONOUNS[category][role]\n",
    "                else:\n",
    "                    new_pronoun = DEFAULT_PRONOUNS[\"gender_fair\"][role]\n",
    "\n",
    "                if token.text.istitle():\n",
    "                    new_pronoun = new_pronoun.capitalize()\n",
    "                elif token.text.isupper():\n",
    "                    new_pronoun = new_pronoun.upper()\n",
    "\n",
    "                if new_pronoun.lower() != token.text.lower():\n",
    "                    corrections.append({\n",
    "                        \"word_index\": token.i,\n",
    "                        \"original_text\": token.text,\n",
    "                        \"replacements\": [new_pronoun],\n",
    "                        \"character_offset\": token.idx,\n",
    "                        \"character_endset\": token.idx + len(token.text)\n",
    "                    })\n",
    "\n",
    "        return corrections\n",
    "\n",
    "    def _filter_overlapping_corrections(self, corrections: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Filter out overlapping corrections, keeping the longest matches.\"\"\"\n",
    "        if not corrections:\n",
    "            return []\n",
    "            \n",
    "        sorted_corrections = sorted(corrections, key=lambda x: (x['character_offset'], -x['character_endset']))\n",
    "        filtered = []\n",
    "        last_end = -1\n",
    "        \n",
    "        for c in sorted_corrections:\n",
    "            if c['character_offset'] >= last_end:\n",
    "                filtered.append(c)\n",
    "                last_end = c['character_endset']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    def process_text(self, text: str, name_pronoun_map: Optional[Dict] = None) -> Dict:\n",
    "        \"\"\"Main processing method that returns original and revised text with corrections.\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            raise ValueError(\"Input text must be a non-empty string\")\n",
    "            \n",
    "        revised_text, corrections = self._process_text_replacements(text, name_pronoun_map or {})\n",
    "        \n",
    "        return {\n",
    "            \"original_text\": text,\n",
    "            \"revised_text\": revised_text,\n",
    "            \"corrections\": sorted([\n",
    "                c for c in corrections if c['character_offset'] >= 0\n",
    "            ], key=lambda x: x['character_offset'])\n",
    "        }\n",
    "\n",
    "def load_gfl(csv_path: str = 'gendered_terms.csv') -> GenderFairLanguage:\n",
    "    return GenderFairLanguage(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GenderFairLanguage' object has no attribute '_adjust_pluralization'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m input_text = \u001b[33m\"\u001b[39m\u001b[33mThe people are going in lady\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms room.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m pronoun_map =  { \u001b[33m\"\u001b[39m\u001b[33mAdam-Silver\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33mgender_fair\u001b[39m\u001b[33m\"\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m result = \u001b[43mgfl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpronoun_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(result, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 416\u001b[39m, in \u001b[36mGenderFairLanguage.process_text\u001b[39m\u001b[34m(self, text, name_pronoun_map)\u001b[39m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput text must be a non-empty string\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m revised_text, corrections = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_text_replacements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_pronoun_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    419\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moriginal_text\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m    420\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrevised_text\u001b[39m\u001b[33m\"\u001b[39m: revised_text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m     ], key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m'\u001b[39m\u001b[33mcharacter_offset\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    424\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mGenderFairLanguage._process_text_replacements\u001b[39m\u001b[34m(self, text, name_pronoun_map)\u001b[39m\n\u001b[32m    128\u001b[39m corrections = []\n\u001b[32m    129\u001b[39m corrections.extend(\u001b[38;5;28mself\u001b[39m._find_gender_pairs(text, doc))\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m corrections.extend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_find_adjective_noun_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    131\u001b[39m corrections.extend(\u001b[38;5;28mself\u001b[39m._find_individual_terms(text, doc))\n\u001b[32m    132\u001b[39m corrections.extend(\u001b[38;5;28mself\u001b[39m._find_pronoun_replacements(text, doc, name_pronoun_map))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 299\u001b[39m, in \u001b[36mGenderFairLanguage._find_adjective_noun_pairs\u001b[39m\u001b[34m(self, text, doc)\u001b[39m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (token.text.lower() \u001b[38;5;129;01min\u001b[39;00m GENDER_ADJECTIVES_PAIR_REMOVAL \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    294\u001b[39m         next_token.text == \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[32m    295\u001b[39m         next_next_token \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[32m    296\u001b[39m         next_next_token.pos_ == \u001b[33m\"\u001b[39m\u001b[33mNOUN\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    298\u001b[39m         full_phrase = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnext_token.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_next_token.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m         replacement = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adjust_pluralization\u001b[49m(token.text, next_next_token.text)\n\u001b[32m    301\u001b[39m         corrections.append({\n\u001b[32m    302\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mword_index\u001b[39m\u001b[33m\"\u001b[39m: i,\n\u001b[32m    303\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33moriginal_text\u001b[39m\u001b[33m\"\u001b[39m: full_phrase,\n\u001b[32m   (...)\u001b[39m\u001b[32m    306\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcharacter_endset\u001b[39m\u001b[33m\"\u001b[39m: next_next_token.idx + \u001b[38;5;28mlen\u001b[39m(next_next_token.text)\n\u001b[32m    307\u001b[39m         })\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m corrections\n",
      "\u001b[31mAttributeError\u001b[39m: 'GenderFairLanguage' object has no attribute '_adjust_pluralization'"
     ]
    }
   ],
   "source": [
    "gfl = load_gfl()\n",
    " \n",
    "# Example usage\n",
    "input_text = \"The people are going in lady's room.\"\n",
    "pronoun_map =  { \"Adam-Silver\" : \"gender_fair\" }\n",
    "\n",
    " \n",
    "result = gfl.process_text(input_text, pronoun_map)\n",
    "import json\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
