{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13aa026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Constants\n",
    "DEFAULT_PRONOUNS = {\n",
    "    \"male\": {\"subject\": \"he\", \"object\": \"him\", \"possessive\": \"his\", \"reflexive\": \"himself\"},\n",
    "    \"female\": {\"subject\": \"she\", \"object\": \"her\", \"possessive\": \"her\", \"reflexive\": \"herself\"},\n",
    "    \"gender_fair\": {\"subject\": \"they\", \"object\": \"them\", \"possessive\": \"their\", \"reflexive\": \"themselves\"}\n",
    "}\n",
    "\n",
    "GENDER_ADJECTIVES = {\"male\", \"female\", \"lady\", \"gentlemen\", \"boy\", \"girl\", \"man\", \"woman\"}\n",
    "GENDER_PAIRS = {\n",
    "    (\"girl\", \"boy\"): [\"children\", \"kids\", \"students\", \"youth\", \"young people\"],\n",
    "    (\"son\", \"daughter\"): [\"children\", \"kids\", \"offspring\"],\n",
    "    (\"woman\", \"man\"): [\"people\", \"individuals\", \"persons\"],\n",
    "    (\"women\", \"men\"): [\"people\", \"individuals\", \"persons\"],\n",
    "    (\"he\", \"she\"): [\"they\"],\n",
    "    (\"his\", \"her\"): [\"their\"],\n",
    "    (\"him\", \"her\"): [\"them\"],\n",
    "    (\"himself\", \"herself\"): [\"themselves\"],\n",
    "    (\"husband\", \"wife\"): [\"spouse\", \"partner\"],\n",
    "    (\"boyfriend\", \"girlfriend\"): [\"partner\"],\n",
    "    (\"brother\", \"sister\"): [\"sibling\"],\n",
    "    (\"father\", \"mother\"): [\"parent\"],\n",
    "    (\"uncle\", \"aunt\"): [\"relative\"],\n",
    "    (\"nephew\", \"niece\"): [\"relative\"],\n",
    "    (\"ladies\", \"gentlemen\"): [\"everyone\", \"all\"]\n",
    "}\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class GenderFairLanguage:\n",
    "    def __init__(self, terms_csv: str = 'gendered_terms.csv'):\n",
    "        self.gendered_terms = self._load_and_prioritize_terms(terms_csv)\n",
    "        \n",
    "    def _load_and_prioritize_terms(self, csv_filename: str) -> OrderedDict:\n",
    "        \"\"\"Load and prioritize gendered terms from CSV with multiple replacements.\"\"\"\n",
    "        gendered_terms = OrderedDict()\n",
    "        try:\n",
    "            with open(csv_filename, 'r') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                for row in reader:\n",
    "                    if len(row) >= 2:\n",
    "                        term = row[0].strip().lower()\n",
    "                        replacements = [repl.strip() for repl in row[1:] if repl.strip()]\n",
    "                        if term and replacements:\n",
    "                            gendered_terms[term] = replacements\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading gendered terms: {e}\")\n",
    "            \n",
    "        return OrderedDict(\n",
    "            sorted(gendered_terms.items(), key=lambda item: len(item[0].split()), reverse=True)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _adjust_pluralization(adjective: str, noun: str) -> str:\n",
    "        \"\"\"Proper static method implementation for plural adjustment.\"\"\"\n",
    "        adj_lower = adjective.lower()\n",
    "        noun_lower = noun.lower()\n",
    "        \n",
    "        # Handle irregular plurals\n",
    "        irregular_plurals = {\n",
    "            \"children\": \"child\",\n",
    "            \"people\": \"person\",\n",
    "            \"women\": \"woman\",\n",
    "            \"men\": \"man\"\n",
    "        }\n",
    "        \n",
    "        # Check if noun is plural\n",
    "        is_noun_plural = (\n",
    "            noun_lower.endswith('s') or \n",
    "            noun_lower in irregular_plurals.values()\n",
    "        )\n",
    "        \n",
    "        # Check if adjective is plural\n",
    "        is_adj_plural = (\n",
    "            adj_lower.endswith('s') or \n",
    "            adj_lower in irregular_plurals\n",
    "        )\n",
    "        \n",
    "        # Maintain plural consistency\n",
    "        if is_adj_plural and not is_noun_plural:\n",
    "            return f\"{noun}s\" if not noun.endswith('s') else noun\n",
    "        elif not is_adj_plural and is_noun_plural:\n",
    "            return noun[:-1] if noun.endswith('s') else noun\n",
    "        return noun\n",
    "    \n",
    "    @staticmethod\n",
    "    def _adjust_capitalization(original: str, replacement: str) -> str:\n",
    "        \"\"\"Preserve capitalization patterns in replacements.\"\"\"\n",
    "        if original.isupper():\n",
    "            return replacement.upper()\n",
    "        elif original.istitle():\n",
    "            return replacement.capitalize()\n",
    "        return replacement.lower()\n",
    "\n",
    "    def _is_within_quotes(self, doc, start_idx: int, end_idx: int) -> bool:\n",
    "        \"\"\"Check if text is within double quotes in the original text.\"\"\"\n",
    "        text = doc.text\n",
    "        before = len(re.findall(r'(?<!\\\\)\"', text[:start_idx]))\n",
    "        after = len(re.findall(r'(?<!\\\\)\"', text[end_idx:]))\n",
    "        return (before % 2 == 1) and (after % 2 == 1)\n",
    "\n",
    "    def _process_text_replacements(self, text: str, name_pronoun_map: Dict) -> Tuple[str, List[Dict]]:\n",
    "        \"\"\"Main text processing with hyphen-aware name handling.\"\"\"\n",
    "        doc = nlp(text)\n",
    "        # Enhanced title detection with hyphen handling\n",
    "\n",
    "        TITLE_MAPPING = {\n",
    "                        'mr': 'male',\n",
    "                        'ms': 'female', \n",
    "                        'mrs': 'female', \n",
    "                        'mx': 'gender_fair',\n",
    "                        'sir': 'male',\n",
    "                        'madam': \"female\",\n",
    "                         }\n",
    "        i = 0\n",
    "        while i < len(doc):\n",
    "            token = doc[i]\n",
    "            base_title = token.text.lower().rstrip('.')\n",
    "\n",
    "            if base_title in TITLE_MAPPING:\n",
    "                name_parts = [token.text]\n",
    "                j = i + 1\n",
    "                hyphen_buffer = None  # Track hyphens for merging\n",
    "\n",
    "                while j < len(doc):\n",
    "                    current_token = doc[j]\n",
    "                    current_text = current_token.text\n",
    "\n",
    "                    # Handle hyphen merging\n",
    "                    if current_text == '-':\n",
    "                        hyphen_buffer = current_text\n",
    "                    elif hyphen_buffer and current_token.pos_ == 'PROPN':\n",
    "                        # Merge hyphen with next word\n",
    "                        name_parts.append(hyphen_buffer + current_text)\n",
    "                        hyphen_buffer = None\n",
    "                    elif current_token.pos_ == 'PROPN' or (current_text in ['-'] and not hyphen_buffer):\n",
    "                        name_parts.append(current_text)\n",
    "                    else:\n",
    "                        break\n",
    "                    \n",
    "                    j += 1\n",
    "\n",
    "                if len(name_parts) > 1:\n",
    "                    # Clean and normalize names\n",
    "                    full_name = self._normalize_hyphenated_name(' '.join(name_parts))\n",
    "                    name_without_title = self._normalize_hyphenated_name(' '.join(name_parts[1:]))\n",
    "\n",
    "                    category = TITLE_MAPPING[base_title]\n",
    "                    name_pronoun_map[full_name.lower()] = category\n",
    "                    name_pronoun_map[name_without_title.lower()] = category\n",
    "\n",
    "                i = j - 1  # Skip processed tokens\n",
    "            i += 1\n",
    "\n",
    "        # Rest of processing remains\n",
    "        corrections = []\n",
    "        corrections.extend(self._find_gender_pairs(text, doc))\n",
    "        corrections.extend(self._find_adjective_noun_pairs(text, doc))\n",
    "        corrections.extend(self._find_individual_terms(text, doc))\n",
    "        corrections.extend(self._find_pronoun_replacements(text, doc, name_pronoun_map))\n",
    "        corrections = self._filter_overlapping_corrections(corrections)\n",
    "\n",
    "        revised_text = text\n",
    "        for correction in sorted(corrections, key=lambda x: -x['character_offset']):\n",
    "            replacement_str = correction['replacements'][0]\n",
    "            revised_text = revised_text[:correction['character_offset']] + replacement_str + revised_text[correction['character_endset']:]\n",
    "\n",
    "        return revised_text, corrections\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_hyphenated_name(name: str) -> str:\n",
    "        \"\"\"Merge hyphen patterns into proper hyphenated format.\"\"\"\n",
    "        return re.sub(r'\\s*-\\s*', '-', name).strip()\n",
    "\n",
    "    def _find_pronoun_replacements(self, text: str, doc, name_pronoun_map: Dict) -> List[Dict]:\n",
    "        \"\"\"Pronoun resolution with enhanced name tracking.\"\"\"\n",
    "        corrections = []\n",
    "        name_to_category = {name.lower(): category for name, category in name_pronoun_map.items()}\n",
    "        processed_names = set(name_to_category.keys())\n",
    "\n",
    "        # Track all name variants from titles\n",
    "        name_variants = []\n",
    "        for name in processed_names:\n",
    "            name_variants.extend([\n",
    "                name,\n",
    "                name.replace('-', ' '),  # \"adam-silver\" -> \"adam silver\"\n",
    "                name.replace(' ', '-')    # \"adam silver\" -> \"adam-silver\"\n",
    "            ])\n",
    "\n",
    "        NEUTRAL_PRONOUNS = {\"i\", \"me\", \"my\", \"mine\", \"myself\",\n",
    "                            \"we\", \"us\", \"our\", \"ours\", \"ourselves\",\n",
    "                            \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "                            \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"it\", \"its\", \"itself\"}\n",
    "\n",
    "        for token in doc:\n",
    "            if (token.tag_ in [\"PRP\", \"PRP$\"] and \n",
    "                token.text.lower() not in NEUTRAL_PRONOUNS and\n",
    "                not self._is_within_quotes(doc, token.idx, token.idx + len(token.text))):\n",
    "\n",
    "                # Find closest matching name in previous context\n",
    "                referent = None\n",
    "                lookback_window = doc[max(0, token.i-10):token.i]  # 10 tokens back\n",
    "                for prev_token in reversed(lookback_window):\n",
    "                    if prev_token.pos_ == 'PROPN':\n",
    "                        candidate = self._normalize_hyphenated_name(prev_token.text).lower()\n",
    "                        if candidate in processed_names:\n",
    "                            referent = candidate\n",
    "                            break\n",
    "                        # Check space/hyphen variants\n",
    "                        for variant in [candidate, candidate.replace('-', ' ')]:\n",
    "                            if variant in name_to_category:\n",
    "                                referent = variant\n",
    "                                break\n",
    "                        if referent:\n",
    "                            break\n",
    "\n",
    "                # Fallback to entity resolution\n",
    "                if not referent:\n",
    "                    for ent in reversed(doc.ents):\n",
    "                        if ent.end <= token.i and ent.label_ in [\"PERSON\", \"ORG\"]:\n",
    "                            candidate = self._normalize_hyphenated_name(ent.text).lower()\n",
    "                            if candidate in processed_names:\n",
    "                                referent = candidate\n",
    "                                break\n",
    "\n",
    "                # Determine pronoun role and replacement\n",
    "                if referent:\n",
    "                    category = name_to_category[referent]\n",
    "                    role = self._get_pronoun_role(token)\n",
    "                    new_pronoun = DEFAULT_PRONOUNS[category][role]\n",
    "                else:\n",
    "                    new_pronoun = DEFAULT_PRONOUNS[\"gender_fair\"][self._get_pronoun_role(token)]\n",
    "\n",
    "                # Apply capitalization and replacement\n",
    "                new_pronoun = self._adjust_capitalization(token.text, new_pronoun)\n",
    "                if new_pronoun != token.text:\n",
    "                    corrections.append({\n",
    "                        \"word_index\": token.i,\n",
    "                        \"original_text\": token.text,\n",
    "                        \"replacements\": [new_pronoun],\n",
    "                        \"character_offset\": token.idx,\n",
    "                        \"character_endset\": token.idx + len(token.text)\n",
    "                    })\n",
    "\n",
    "        return corrections\n",
    "\n",
    "    def _get_pronoun_role(self, token) -> str:\n",
    "        \"\"\"Determine pronoun grammatical role.\"\"\"\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "            return \"subject\"\n",
    "        if token.dep_ in [\"dobj\", \"iobj\", \"pobj\"]:\n",
    "            return \"object\"\n",
    "        if token.dep_ == \"poss\" or token.tag_ == \"PRP$\":\n",
    "            return \"possessive\"\n",
    "        if token.dep_ == \"reflexive\":\n",
    "            return \"reflexive\"\n",
    "        return \"subject\"  # Default fallback\n",
    "\n",
    "    def _find_gender_pairs(self, text: str, doc) -> List[Dict]:\n",
    "        \"\"\"Find specific gender pairs to replace with more inclusive terms.\"\"\"\n",
    "        corrections = []\n",
    "\n",
    "        for (term1, term2), replacements in GENDER_PAIRS.items():\n",
    "             for t1, t2 in [(term1, term2), (term2, term1)]:\n",
    "                term1_variants = [t1, t1 + 's', t1 + 'es']\n",
    "                term2_variants = [t2, t2 + 's', t2 + 'es']\n",
    "\n",
    "                for v1 in term1_variants:\n",
    "                    for v2 in term2_variants:\n",
    "                        pattern = rf'\\b({v1})\\s+(and|or)\\s+({v2})\\b'\n",
    "                        matches = list(re.finditer(pattern, text, re.IGNORECASE))\n",
    "\n",
    "                        for match in reversed(matches):\n",
    "                            if self._is_within_quotes(doc, match.start(), match.end()):\n",
    "                                continue\n",
    "\n",
    "                            is_or = match.group(2).lower() == \"or\"\n",
    "\n",
    "                            # Handle singular/plural for \"or\" cases\n",
    "                            if is_or:\n",
    "                                adjusted_replacements = []\n",
    "                                for repl in replacements:\n",
    "                                    if repl.endswith('s'):\n",
    "                                        adjusted = repl[:-1]  # children -> child\n",
    "                                    elif repl.endswith('es'):\n",
    "                                        adjusted = repl[:-2]  # ladies -> lady\n",
    "                                    else:\n",
    "                                        adjusted = repl\n",
    "                                    adjusted_replacements.append(adjusted)\n",
    "                            else:\n",
    "                                adjusted_replacements = replacements\n",
    "\n",
    "                            first_word = match.group(1)\n",
    "                            adjusted_replacements = [\n",
    "                                self._adjust_capitalization(first_word, repl)\n",
    "                                for repl in adjusted_replacements\n",
    "                            ]\n",
    "\n",
    "                            corrections.append({\n",
    "                                \"word_index\": next((i for i, t in enumerate(doc) if t.idx <= match.start() < t.idx + len(t.text)), None),\n",
    "                                \"original_text\": match.group(0),\n",
    "                                \"replacements\": adjusted_replacements,\n",
    "                                \"character_offset\": match.start(),\n",
    "                                \"character_endset\": match.end()\n",
    "                            })\n",
    "\n",
    "        return corrections\n",
    "\n",
    "\n",
    "    def _find_adjective_noun_pairs(self, text: str, doc) -> List[Dict]:\n",
    "        \"\"\"Enhanced adjective-noun pair handling with proper static method calls.\"\"\"\n",
    "        corrections = []\n",
    "        GENDER_ADJECTIVES_PAIR_REMOVAL = {\"male\", \"female\", \"lady\", \"gentlemen\", \"boy\", \"girl\", \"lady's\"}\n",
    "\n",
    "        for i in range(len(doc) - 1):\n",
    "            token = doc[i]\n",
    "            next_token = doc[i + 1]\n",
    "\n",
    "            # Process adjective removal pairs\n",
    "            if (token.text.lower() in GENDER_ADJECTIVES_PAIR_REMOVAL and \n",
    "                next_token.pos_ == \"NOUN\"):\n",
    "\n",
    "                # Get replacement with proper pluralization\n",
    "                replacement = self._adjust_pluralization(\n",
    "                    adjective=token.text,\n",
    "                    noun=next_token.text\n",
    "                )\n",
    "\n",
    "                # Create correction entry\n",
    "                corrections.append({\n",
    "                    \"word_index\": i,\n",
    "                    \"original_text\": f\"{token.text} {next_token.text}\",\n",
    "                    \"replacements\": [replacement],\n",
    "                    \"character_offset\": token.idx,\n",
    "                    \"character_endset\": next_token.idx + len(next_token.text)\n",
    "                })\n",
    "\n",
    "\n",
    "            elif (token.text.lower() in GENDER_ADJECTIVES and \n",
    "                next_token.pos_ == \"NOUN\" and\n",
    "                not self._is_within_quotes(doc, token.idx, next_token.idx + len(next_token.text))):\n",
    "\n",
    "                noun_replacements = self.gendered_terms.get(next_token.text.lower(), [next_token.text])\n",
    "                adjusted_replacements = [\n",
    "                    self._adjust_capitalization(next_token.text, repl)\n",
    "                    for repl in noun_replacements\n",
    "                ]\n",
    "\n",
    "                corrections.append({\n",
    "                    \"word_index\": i,\n",
    "                    \"original_text\": f\"{token.text} {next_token.text}\",\n",
    "                    \"replacements\": adjusted_replacements,\n",
    "                    \"character_offset\": token.idx,\n",
    "                    \"character_endset\": next_token.idx + len(next_token.text)\n",
    "                })\n",
    "    \n",
    "        return corrections\n",
    "\n",
    "\n",
    "    def _find_individual_terms(self, text: str, doc) -> List[Dict]:\n",
    "        \"\"\"Find individual gendered terms.\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        for term, replacements_list in self.gendered_terms.items():\n",
    "            if ' ' in term:\n",
    "                continue\n",
    "            \n",
    "            for match in reversed(list(re.finditer(rf'\\b{re.escape(term)}\\b', text, re.IGNORECASE))):\n",
    "                if self._is_within_quotes(doc, match.start(), match.end()):\n",
    "                    continue\n",
    "                \n",
    "                original_text = match.group(0)\n",
    "                adjusted_replacements = [self._adjust_capitalization(original_text, repl) for repl in replacements_list]\n",
    "                \n",
    "                corrections.append({\n",
    "                    \"word_index\": next((i for i, t in enumerate(doc) if t.idx <= match.start() < t.idx + len(t.text)), None),\n",
    "                    \"original_text\": original_text,\n",
    "                    \"replacements\": adjusted_replacements,\n",
    "                    \"character_offset\": match.start(),\n",
    "                    \"character_endset\": match.end()\n",
    "                })\n",
    "        \n",
    "        return corrections\n",
    "\n",
    "    def _find_pronoun_replacements(self, text: str, doc, name_pronoun_map: Dict) -> List[Dict]:\n",
    "        \"\"\"Find pronoun replacements with fallback to gender-fair language.\"\"\"\n",
    "        corrections = []\n",
    "        name_to_category = {name.lower(): category for name, category in (name_pronoun_map or {}).items()}\n",
    "\n",
    "        person_entities = [ent for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\"]]\n",
    "        NEUTRAL_PRONOUNS = {\"i\", \"me\", \"my\", \"mine\", \"myself\",\n",
    "                            \"we\", \"us\", \"our\", \"ours\", \"ourselves\",\n",
    "                            \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "                            \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"it\", \"its\", \"itself\"}\n",
    "\n",
    "        for token in doc:\n",
    "            if (token.tag_ in [\"PRP\", \"PRP$\"] and \n",
    "                token.text.lower() not in NEUTRAL_PRONOUNS and\n",
    "                not self._is_within_quotes(doc, token.idx, token.idx + len(token.text))):\n",
    "\n",
    "                referent = None\n",
    "                for ent in reversed(person_entities[:token.i]):\n",
    "                    if ent.end <= token.i:\n",
    "                        referent = ent.text\n",
    "                        break\n",
    "                \n",
    "                if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "                    role = \"subject\"\n",
    "                elif token.dep_ in [\"dobj\", \"iobj\", \"pobj\"]:\n",
    "                    role = \"object\"\n",
    "                elif token.dep_ == \"poss\" or token.tag_ == \"PRP$\":\n",
    "                    role = \"possessive\"\n",
    "                elif token.dep_ == \"reflexive\":\n",
    "                    role = \"reflexive\"\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                if referent and referent.lower() in name_to_category:\n",
    "                    category = name_to_category[referent.lower()]\n",
    "                    new_pronoun = DEFAULT_PRONOUNS[category][role]\n",
    "                else:\n",
    "                    new_pronoun = DEFAULT_PRONOUNS[\"gender_fair\"][role]\n",
    "\n",
    "                if token.text.istitle():\n",
    "                    new_pronoun = new_pronoun.capitalize()\n",
    "                elif token.text.isupper():\n",
    "                    new_pronoun = new_pronoun.upper()\n",
    "\n",
    "                if new_pronoun.lower() != token.text.lower():\n",
    "                    corrections.append({\n",
    "                        \"word_index\": token.i,\n",
    "                        \"original_text\": token.text,\n",
    "                        \"replacements\": [new_pronoun],\n",
    "                        \"character_offset\": token.idx,\n",
    "                        \"character_endset\": token.idx + len(token.text)\n",
    "                    })\n",
    "\n",
    "        return corrections\n",
    "\n",
    "    def _filter_overlapping_corrections(self, corrections: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Filter out overlapping corrections, keeping the longest matches.\"\"\"\n",
    "        if not corrections:\n",
    "            return []\n",
    "            \n",
    "        sorted_corrections = sorted(corrections, key=lambda x: (x['character_offset'], -x['character_endset']))\n",
    "        filtered = []\n",
    "        last_end = -1\n",
    "        \n",
    "        for c in sorted_corrections:\n",
    "            if c['character_offset'] >= last_end:\n",
    "                filtered.append(c)\n",
    "                last_end = c['character_endset']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    def process_text(self, text: str, name_pronoun_map: Optional[Dict] = None) -> Dict:\n",
    "        \"\"\"Main processing method that returns original and revised text with corrections.\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            raise ValueError(\"Input text must be a non-empty string\")\n",
    "            \n",
    "        revised_text, corrections = self._process_text_replacements(text, name_pronoun_map or {})\n",
    "        \n",
    "        return {\n",
    "            \"original_text\": text,\n",
    "            \"revised_text\": revised_text,\n",
    "            \"corrections\": sorted([\n",
    "                c for c in corrections if c['character_offset'] >= 0\n",
    "            ], key=lambda x: x['character_offset'])\n",
    "        }\n",
    "\n",
    "def load_gfl(csv_path: str = 'gendered_terms.csv') -> GenderFairLanguage:\n",
    "    return GenderFairLanguage(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7e7515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"original_text\": \"Mr. adam silver is businessperson\",\n",
      "  \"revised_text\": \"Mr. adam silver is businessperson\",\n",
      "  \"corrections\": [\n",
      "    {\n",
      "      \"word_index\": 4,\n",
      "      \"original_text\": \"businessperson\",\n",
      "      \"replacements\": [\n",
      "        \"businessperson\"\n",
      "      ],\n",
      "      \"character_offset\": 19,\n",
      "      \"character_endset\": 33\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "gfl = load_gfl()\n",
    " \n",
    "# Example usage\n",
    "input_text = \"Mr. adam silver is businessperson\"\n",
    "pronoun_map =  { \"Adam Silver\" : \"gender_fair\" }\n",
    "\n",
    " \n",
    "result = gfl.process_text(input_text, pronoun_map)\n",
    "import json\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
