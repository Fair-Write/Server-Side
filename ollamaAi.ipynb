{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United States is Washington, D.C., which stands for \"District of Columbia.\" It's where the federal government's executive and legislative branches are located, including the White House (executive residence), Congress, Supreme Court buildings, and other important national institutions.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model='phi3.5', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'What is capital of usa?',\n",
    "  },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programming\\project\\gfl-api\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 0 examples [00:00, ? examples/s]Failed to read file 'E:\\Programming\\project\\gfl-api\\datasets.csv' with error <class 'pandas.errors.ParserError'>: Error tokenizing data. C error: Expected 2 fields in line 15, saw 3\n",
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while loading the dataset: An error occurred while generating the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]Failed to read file 'E:\\Programming\\project\\gfl-api\\datasets.csv' with error <class 'pandas.errors.ParserError'>: Error tokenizing data. C error: Expected 2 fields in line 15, saw 3\n",
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while loading the dataset: An error occurred while generating the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the CSV file with error handling\n",
    "    dataset = load_dataset('csv', data_files='datasets.csv', delimiter=',', on_bad_lines='skip')\n",
    "    # View the dataset structure\n",
    "    print(dataset)\n",
    "    print(dataset['train'].head())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the dataset: {e}\")\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset('csv', data_files={\n",
    "        'train': 'datasets.csv',\n",
    "        'test': 'datasets.csv'\n",
    "    }, delimiter=',', on_bad_lines='skip')\n",
    "    print(dataset)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the dataset: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "Untitled"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
